### 1.hashmap 和 LinkedHashMap 和 TreeMap 和 HashTable 和 ConcurrentHashMap 介绍
#### 1.hashmap?
       hashmap 1.为线程不安全的,所以效率相对来说高一些
               2.底层为数据+链表(jdk1.7之前)
               3.允许key/value为null,key不可以重复,value不能重复
       hashmap的put方法
 ![Alt](https://upload-images.jianshu.io/upload_images/7853175-a8950349acda7799.png?,mageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp =30x30)分析整个put过程得出结果
    首先在1.7之前 hashmap的底层是数组加链表,我们都知道hashmap是线程不安全的,而且存储的数据都可以为null,而线程不安全的情况下我们对数组进行扩容的时候会出现一个死循环,当链表长度大于8数组大于等于64的时候是红黑树,红黑树节点个数小于6的时候转化为链表
    hashmap的插入?
    	首先初始化一个数组的长度,判断数组是否为空,如果不为空插入数据
    多线程的情况下会出现什么问题?多线程put后可能导致get死循环,多线程put的时候可能导致元素丢失,put非null元素后get出来的却是null


#### 2.HashTable?
       1.底层为数组+链表实现
       2.key和 value都不为空 
       3.线程安全的(实现线程安全的方法是在修改数据时,锁住整个hashtable(分段锁)),效率较低
       4.初始化size为11,扩容为 newsize = oldsize*2+1

#### 3.TreeMap?
      1.基于红黑书
      2.线程不安全
      3.key值不允许为null,key不可以重复,value可以重复

#### 4.LinkedHashMap?
       介绍之前我们都知道,hashmap为数组+单向链表,linkedList为双向链表实现,所以linkedHashMap为(linkedlist+hashmap)的集合,linkedHashmap继承自hashmap,它新增put和获取get的方法都是复用父类HashMap的代码,只是重写了put给get内部的某些接口,
       1.LinkedHashMap数据存储和hashmap相同,数组+单向链表,只是在每次的Entry中增加了用于维护顺序的before和after变量来维护一个双向链表来保存

#### 5.ConcurrentHashMap?
       1.底层是分段的数组+链表实现 线程安全
       2.通过把整个map分为N个Segment,可以提供相同的线程安全,但是效率提升N倍,默认提升16倍,(读操作不加锁,由于HashEntry的value变量是volatile的,也能包区读取到最新的值)
       3.Hashtable的synchronized是针对整张Hash表的,即每次锁住整张表让线程独占ConcurrentHashMap允许多个修改操作并发进行,其关键在于使用了锁分离技术

### 6.hashSet有什么功能,基于那个类实现?
      1.存的元素不能为空,元素不能重复
      2.基于hashMap实现

### 7.ConcurrentHashMap并发能力为什么比HashTable好?
      1.HashTable是通过对hash表整体进行锁定,是阻塞式的,当一个线程占有这个锁的时候,其他线程必须阻塞当前线程释放锁
      2.而ConcurrentHashMap的实现则是(1.6)采用Segment分段锁的方式,他并没有对这个数据结构进行锁定,而是局部锁
      3.jdk1.8之后采用了一种乐观锁的CAS 算法来实现同步问题,但是底层还是数据+链表+红黑树实现

### 4.hashmap和ConcurrentHashMap的区别?
    hashmap是线程不安全的,底层是数组+链表+红黑树(1.7后),存储的数据key和value可以为null,
    ConcurrentHashMap是线程安全的,并不是每个方法都加上了synchronized修饰方法,那不成了hashtable了,底层其实是映入了一个分段锁的概念,具体可以理解为把一个大的map拆分为多个小的hashtable,更具key.hashCode()来决定把key放到那个hashtable中,在ConcurrentHashMap中把map拆分了n个Segmentput和get的时候，都是现根据key.hashCode()算出放到哪个Segment中：

### 5.List的初始化大小和扩容机制
    list的初始化大小是0当list里面add数据之后,初始容量就会变成10,而扩容的机制是当发现当前扩容机制不够用的时候,就会扩容,也就是当抢扩容机制为大于等于10的时候回去扩容,arrayListd的扩容是原容量的1.5倍
